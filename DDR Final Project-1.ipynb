{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Project\n",
    "____Group 8____\n",
    "\n",
    "Mandy Gu\n",
    "\n",
    "Tejasvini Karunakarbabu\n",
    "\n",
    "Mayank Mani\n",
    "\n",
    "Willa Yu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Import all packages needed__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mysql.connector\n",
    "from sqlalchemy import create_engine\n",
    "import pymysql\n",
    "import json\n",
    "import time\n",
    "from datetime import date\n",
    "from dateutil.parser import parse\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup \n",
    "from tqdm import notebook\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import datetime\n",
    "import re\n",
    "from datetime import timedelta\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1. Store the to-be-scraped pages and other necassary information.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the company list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies = ['FB', 'EXPEDIA', 'COSTCO', 'GOOGL', 'ADBE', 'SBUX', 'TSLA', 'NFLX', 'AAPL', 'AMZN']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Nasdaq uses a dynamic web structure, launch the webdriver to get the page contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the directory for storing all the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = os.getcwd()+'\\\\news'\n",
    "if not os.path.exists(test1):\n",
    "    os.makedirs(test1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all the pages that we need using webdriver, store them in the 'news' directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list_t = []\n",
    "current_time_list_t = []\n",
    "\n",
    "for company in notebook.tqdm(companies):\n",
    "    # create a 50-page list for testing\n",
    "    url_list = [str('https://www.nasdaq.com/search?q='+ company + '&page='+ str(i)+ '&sort_by=recent') for i in range(1,51)]\n",
    "    page_num = 1\n",
    "    # get the time the selenium is started\n",
    "    current_time = datetime.datetime.now()\n",
    "    \n",
    "    # download the page\n",
    "    for url in notebook.tqdm(url_list):\n",
    "        driver.get(url)\n",
    "        pagesource = driver.page_source\n",
    "        time.sleep(2)\n",
    "        file_name = str(company) + ' ' + str(page_num) + '.txt'\n",
    "        name_wdir = os.path.join(test1, file_name)\n",
    "        file = open(name_wdir, 'w',  encoding = \"utf-8\")\n",
    "        file.write(str(pagesource))\n",
    "        file.close()\n",
    "        page_num = page_num + 1\n",
    "        company_list_t.append(company)\n",
    "        current_time_list_t.append(current_time)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the company and current_time to a csv for future use (and read it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_cnt = pd.DataFrame({\n",
    "    'company': company_list_t,\n",
    "    'current_time': current_time_list_t,\n",
    "    })\n",
    "name_wdir_csv1 = os.path.join(test1, 'news_company_n_time.csv')\n",
    "news_cnt.to_csv(name_wdir_csv1, index = False)\n",
    "\n",
    "# read the csv with company name and current time \n",
    "news_cnt1 = pd.read_csv(name_wdir_csv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the file names of the scraped txts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_list = []\n",
    "for company in companies:\n",
    "    page_list = list(page_list + [company + ' ' + str(i) + '.txt' for i in range(1,51)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the function to calculate publish day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def day_calculator(time):\n",
    "    '''\n",
    "    get the date of news\n",
    "    ''' \n",
    "    if bool(re.search('DAY', time.text, re.IGNORECASE)):\n",
    "        day_delta = int((re.findall('([0-9]+)', time.text)[0]))\n",
    "        day_diff = timedelta(days = day_delta)\n",
    "        press_day = (current_time - day_diff).date()\n",
    "    elif bool(re.search('HOUR', time.text, re.IGNORECASE)):\n",
    "        hour_delta = int((re.findall('([0-9]+)', time.text)[0]))\n",
    "        hour_diff = timedelta(hours = hour_delta)\n",
    "        press_day = (current_time - hour_diff).date()\n",
    "    elif bool(re.search('MIN', time.text, re.IGNORECASE)):\n",
    "        press_day = (current_time).date()\n",
    "    elif time.text == '':\n",
    "        press_day = ''\n",
    "    else:\n",
    "        press_day = parse(time.text).date()\n",
    "    return press_day\n",
    "day_calculate = lambda x: day_calculator(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__2. Scrape news headlines, related company name, published time, and publisher from the stored text files.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = []\n",
    "titles_list = []\n",
    "publisher_list = []\n",
    "page_url_list = []\n",
    "url_list = []\n",
    "release_date_list = []\n",
    "weekday_list = []\n",
    "weekday = []\n",
    "try_list = []\n",
    "titles_count = []\n",
    "\n",
    "for i in notebook.tqdm(range(len(page_list))):\n",
    "    # Open the file\n",
    "    name_wdir2 = os.path.join(test1, page_list[i])\n",
    "    page_content = open(name_wdir2, \"r\", encoding=\"utf-8\").read()\n",
    "    # Assign a list to the file\n",
    "    soup = BeautifulSoup(page_content)\n",
    "    \n",
    "    try_list.append(page_list[i])\n",
    "    # get the searched company neme for this page\n",
    "    company_name = re.sub(r'([A-Z]+)( [0-9]+.*)', r'\\1', page_list[i])\n",
    "    # get the list of titles\n",
    "    title_container = soup.find_all(class_ = 'search-result__link')\n",
    "    titles = [x.text for x in title_container]\n",
    "    titles_count.append(len(titles))\n",
    "    # get the list of news release time: e.g. '1 minute ago', 26 DAYS AGO'\n",
    "    current_time = parse(news_cnt1.loc[:,'current_time'][i//50])\n",
    "    press_time = soup.find_all(class_ = 'search-result__date')\n",
    "    release_date = list(map(day_calculate, press_time))\n",
    "    for x in release_date:\n",
    "        if x == '':\n",
    "            weekday.append('')\n",
    "        else:\n",
    "            weekday.append(x.isoweekday()) \n",
    "#     weekday = [x.isoweekday() for x in release_date]\n",
    "    # get the publisher\n",
    "    footer = soup.find_all(class_ = 'search-result__footer')\n",
    "    publisher = []\n",
    "    for content in footer:\n",
    "        if content.find(class_ = 'search-result__topic') is None:\n",
    "            publisher.append('No publisher')\n",
    "        else:\n",
    "            publisher.append(content.find(class_ = 'search-result__topic').text)\n",
    "    # get the url\n",
    "    page_url = ['https://www.nasdaq.com' + x[\"href\"] for x in title_container]\n",
    "\n",
    "        \n",
    "    # create a list for each page      \n",
    "    company_list = list(company_list + [company_name for i in range(len(titles))]) # every page contains 10 news\n",
    "    titles_list = list(titles_list + titles)\n",
    "    release_date_list = list(release_date_list + release_date)\n",
    "    publisher_list = list(publisher_list + publisher)\n",
    "    page_url_list = list(page_url_list + page_url)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataframe \n",
    "news_df = pd.DataFrame({\n",
    "    'company': company_list,\n",
    "    'titles': titles_list,\n",
    "    'release_date': release_date_list,\n",
    "    'weekday': weekday,\n",
    "    'publisher': publisher_list,\n",
    "    'page_url': page_url_list\n",
    "})\n",
    "news_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the dataframe as csv to the directory\n",
    "name_wdir3 = os.path.join(test1, \"news_list.csv\")\n",
    "news_df.to_csv(name_wdir3, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the stored dataframe\n",
    "csv_path = test1 + \"\\\\news_list.csv\"\n",
    "news_df2 = pd.read_csv(csv_path)\n",
    "news_df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__3. Get the article contents and 'other topics' in the news as weight__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list = news_df.copy()\n",
    "page_url_sub = full_list.loc[:, 'page_url']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_all_news = []\n",
    "weight_all_news = []\n",
    "texter = lambda x: x.text\n",
    "\n",
    "for url in notebook.tqdm(page_url_sub):\n",
    "    driver.get(url)\n",
    "    par_str = ''\n",
    "    for par in driver.find_elements_by_class_name('body__content')[:-3]:\n",
    "        par_str = par_str + '\\n' + par.text\n",
    "    content_all_news.append(par_str)\n",
    "    weight_all_news.append(list(map(texter, driver.find_elements_by_class_name('topics-in-this-story__symbol'))))\n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_list = pd.DataFrame({\n",
    "    'article': content_all_news,\n",
    "    'weights': weight_all_news\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_list_wweight = pd.concat([full_list, weight_list],axis = 1)\n",
    "full_list_wweight.to_excel('full_list_wweight.xlsx', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__4. Get the 10 companies' stock price via API__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "companies_sym = ['FB', 'EXPE', 'COST', 'GOOGL', 'ADBE', 'SBUX', 'TSLA', 'NFLX', 'AAPL', 'AMZN', 'NDAQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9db32b8a3e6492c9f4f0024d506fea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# api_df = pd.DataFrame()\n",
    "cwd = os.getcwd()\n",
    "api_path = cwd + '\\\\api'\n",
    "if not os.path.exists(api_path):\n",
    "    os.makedirs(api_path)\n",
    "\n",
    "# fetch all the apis    \n",
    "for company_sym in notebook.tqdm(companies_sym):\n",
    "    api_url = \"https://www.alphavantage.co/query?function=TIME_SERIES_DAILY_ADJUSTED&symbol=\" + company_sym +\"&apikey=XOJE92KV355K5ZXX\"\n",
    "    api_response = requests.request(\"GET\", api_url)\n",
    "    api_dict = api_response.json()\n",
    "    api_df = pd.DataFrame(api_dict['Time Series (Daily)']).T\n",
    "    api_df['company'] = company_sym\n",
    "    api_file_name = api_path + '\\\\' + company_sym + '_api.xlsx'\n",
    "    api_df.to_excel(api_file_name, index = True)\n",
    "    time.sleep(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pls ensure you have no other xlsx files in this directory\n",
    "api_dfs = pd.DataFrame()\n",
    "for filename in glob.glob(api_path + '\\\\*.xlsx'):\n",
    "    api_read_xlsx = pd.read_excel(filename)\n",
    "    api_dfs = pd.concat([api_dfs, api_read_xlsx])\n",
    "api_dfs = api_dfs.rename(columns={'Unnamed: 0': 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_full_path = api_path + '\\\\api_full.xlsx'\n",
    "api_dfs.to_excel(api_full_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>277.14</td>\n",
       "      <td>286.44</td>\n",
       "      <td>269.37</td>\n",
       "      <td>285.34</td>\n",
       "      <td>285.34</td>\n",
       "      <td>70721316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>263.75</td>\n",
       "      <td>278.09</td>\n",
       "      <td>263.00</td>\n",
       "      <td>266.17</td>\n",
       "      <td>266.17</td>\n",
       "      <td>71686208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>282.00</td>\n",
       "      <td>290.82</td>\n",
       "      <td>281.23</td>\n",
       "      <td>289.03</td>\n",
       "      <td>289.03</td>\n",
       "      <td>56544246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>295.52</td>\n",
       "      <td>299.55</td>\n",
       "      <td>291.41</td>\n",
       "      <td>292.92</td>\n",
       "      <td>292.92</td>\n",
       "      <td>46893219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>296.44</td>\n",
       "      <td>303.40</td>\n",
       "      <td>293.13</td>\n",
       "      <td>302.74</td>\n",
       "      <td>302.74</td>\n",
       "      <td>54794568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2019-10-22</td>\n",
       "      <td>254.32</td>\n",
       "      <td>258.33</td>\n",
       "      <td>250.85</td>\n",
       "      <td>255.58</td>\n",
       "      <td>255.58</td>\n",
       "      <td>4625095</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2019-10-21</td>\n",
       "      <td>258.33</td>\n",
       "      <td>259.50</td>\n",
       "      <td>250.18</td>\n",
       "      <td>253.50</td>\n",
       "      <td>253.50</td>\n",
       "      <td>5020339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2019-10-18</td>\n",
       "      <td>260.70</td>\n",
       "      <td>262.80</td>\n",
       "      <td>255.10</td>\n",
       "      <td>256.95</td>\n",
       "      <td>256.95</td>\n",
       "      <td>5720888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2019-10-17</td>\n",
       "      <td>262.50</td>\n",
       "      <td>264.78</td>\n",
       "      <td>260.17</td>\n",
       "      <td>261.97</td>\n",
       "      <td>261.97</td>\n",
       "      <td>4779043</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2019-10-16</td>\n",
       "      <td>257.39</td>\n",
       "      <td>262.10</td>\n",
       "      <td>256.92</td>\n",
       "      <td>259.75</td>\n",
       "      <td>259.75</td>\n",
       "      <td>6704303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>TSLA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "0   2020-03-10   277.14   286.44  269.37    285.34             285.34   \n",
       "1   2020-03-09   263.75   278.09  263.00    266.17             266.17   \n",
       "2   2020-03-06   282.00   290.82  281.23    289.03             289.03   \n",
       "3   2020-03-05   295.52   299.55  291.41    292.92             292.92   \n",
       "4   2020-03-04   296.44   303.40  293.13    302.74             302.74   \n",
       "..         ...      ...      ...     ...       ...                ...   \n",
       "95  2019-10-22   254.32   258.33  250.85    255.58             255.58   \n",
       "96  2019-10-21   258.33   259.50  250.18    253.50             253.50   \n",
       "97  2019-10-18   260.70   262.80  255.10    256.95             256.95   \n",
       "98  2019-10-17   262.50   264.78  260.17    261.97             261.97   \n",
       "99  2019-10-16   257.39   262.10  256.92    259.75             259.75   \n",
       "\n",
       "    6. volume  7. dividend amount  8. split coefficient company  \n",
       "0    70721316                 0.0                   1.0    AAPL  \n",
       "1    71686208                 0.0                   1.0    AAPL  \n",
       "2    56544246                 0.0                   1.0    AAPL  \n",
       "3    46893219                 0.0                   1.0    AAPL  \n",
       "4    54794568                 0.0                   1.0    AAPL  \n",
       "..        ...                 ...                   ...     ...  \n",
       "95    4625095                 0.0                   1.0    TSLA  \n",
       "96    5020339                 0.0                   1.0    TSLA  \n",
       "97    5720888                 0.0                   1.0    TSLA  \n",
       "98    4779043                 0.0                   1.0    TSLA  \n",
       "99    6704303                 0.0                   1.0    TSLA  \n",
       "\n",
       "[1100 rows x 10 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__5.Create a SQL database for the dataframes__\n",
    "\n",
    "dataframes including news_full_list_with_weight and api_full_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_fulllist = pd.read_excel('full_list_wweight.xlsx', ncoding = \"cp1252\")\n",
    "api_fulllist = pd.read_excel('api_full.xlsx', ncoding = \"cp1252\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>titles</th>\n",
       "      <th>release_date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>publisher</th>\n",
       "      <th>page_url</th>\n",
       "      <th>article</th>\n",
       "      <th>other companies</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Relative Strength Alert For Apple</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BNK Invest</td>\n",
       "      <td>https://www.nasdaq.com/articles/relative-stren...</td>\n",
       "      <td>\\nThe DividendRank formula at Dividend Channel...</td>\n",
       "      <td>['AAPL']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Why Computer Stocks Fell Today</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://www.nasdaq.com/articles/why-computer-s...</td>\n",
       "      <td>\\nWhat happened\\nShares of prominent computer-...</td>\n",
       "      <td>['AMD', 'AAPL', 'MSFT', 'INTC']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>2 Key Trends to Watch in Music Streaming</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://www.nasdaq.com/articles/2-key-trends-t...</td>\n",
       "      <td>\\nStreaming accounted for nearly 80% of U.S. m...</td>\n",
       "      <td>['SPOT', 'AAPL', 'GOOGL', 'SIRI', 'GOOG']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (AAPL) Down 9.8% Since Last Earnings Rep...</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Zacks</td>\n",
       "      <td>https://www.nasdaq.com/articles/apple-aapl-dow...</td>\n",
       "      <td>\\nIt has been about a month since the last ear...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple's Coronavirus Weakness Could Mean Invest...</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://www.nasdaq.com/articles/apples-coronav...</td>\n",
       "      <td>\\nWith worries about the SARS-CoV-2 virus at f...</td>\n",
       "      <td>['AAPL', 'BRK.A', 'BRK.B']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                                             titles release_date  \\\n",
       "0    AAPL                  Relative Strength Alert For Apple    2/27/2020   \n",
       "1    AAPL                     Why Computer Stocks Fell Today    2/27/2020   \n",
       "2    AAPL           2 Key Trends to Watch in Music Streaming    2/27/2020   \n",
       "3    AAPL  Apple (AAPL) Down 9.8% Since Last Earnings Rep...    2/27/2020   \n",
       "4    AAPL  Apple's Coronavirus Weakness Could Mean Invest...    2/27/2020   \n",
       "\n",
       "   weekday        publisher  \\\n",
       "0      4.0       BNK Invest   \n",
       "1      4.0  The Motley Fool   \n",
       "2      4.0  The Motley Fool   \n",
       "3      4.0            Zacks   \n",
       "4      4.0  The Motley Fool   \n",
       "\n",
       "                                            page_url  \\\n",
       "0  https://www.nasdaq.com/articles/relative-stren...   \n",
       "1  https://www.nasdaq.com/articles/why-computer-s...   \n",
       "2  https://www.nasdaq.com/articles/2-key-trends-t...   \n",
       "3  https://www.nasdaq.com/articles/apple-aapl-dow...   \n",
       "4  https://www.nasdaq.com/articles/apples-coronav...   \n",
       "\n",
       "                                             article  \\\n",
       "0  \\nThe DividendRank formula at Dividend Channel...   \n",
       "1  \\nWhat happened\\nShares of prominent computer-...   \n",
       "2  \\nStreaming accounted for nearly 80% of U.S. m...   \n",
       "3  \\nIt has been about a month since the last ear...   \n",
       "4  \\nWith worries about the SARS-CoV-2 virus at f...   \n",
       "\n",
       "                             other companies  \n",
       "0                                   ['AAPL']  \n",
       "1            ['AMD', 'AAPL', 'MSFT', 'INTC']  \n",
       "2  ['SPOT', 'AAPL', 'GOOGL', 'SIRI', 'GOOG']  \n",
       "3                                         []  \n",
       "4                 ['AAPL', 'BRK.A', 'BRK.B']  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_fulllist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create the database for news__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there are many 'other companies' in one news, in order to store it in MySQL, we need to pick only a subset of 'other companies' and split them into several columns.\n",
    "\n",
    "Here we choose __4 as the number of splitted columns__ since the average number of 'other companies' per news is approximately 3.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.493854138213603"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lenlist = []\n",
    "for i in news_fulllist['other companies'].str.strip('[').str.strip(']').str.replace(\"'\",\"\").str.replace(' ','').str.replace('\\n','').str.split(',').tolist():\n",
    "    if type(i) != float:\n",
    "        lenlist.append(len(i))\n",
    "        # avg number of other companies\n",
    "        sum(lenlist)/len(lenlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_list = []\n",
    "for i in news_fulllist['other companies'].str.strip('[').str.strip(']').str.replace(\"'\",\"\").str.replace(' ','').str.replace('\\n','').str.split(',').tolist():\n",
    "    if type(i) == float:\n",
    "        new_list.append(['None'])\n",
    "    elif i[0] == '':\n",
    "        new_list.append(['None'])\n",
    "    else:\n",
    "        new_list.append(i[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "other_companies = pd.DataFrame(new_list, columns = ['other company 1', 'other company 2', 'other company 3', 'other company 4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_fulllist_wide = pd.concat([news_fulllist.drop('other companies', 1), other_companies], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data type of release_date, weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_fulllist_wide['release_date'] = pd.to_datetime(news_fulllist_wide['release_date']).astype(str)\n",
    "news_fulllist_wide['weekday'] = news_fulllist_wide['weekday'].astype('Int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company</th>\n",
       "      <th>titles</th>\n",
       "      <th>release_date</th>\n",
       "      <th>weekday</th>\n",
       "      <th>publisher</th>\n",
       "      <th>page_url</th>\n",
       "      <th>article</th>\n",
       "      <th>other company 1</th>\n",
       "      <th>other company 2</th>\n",
       "      <th>other company 3</th>\n",
       "      <th>other company 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Relative Strength Alert For Apple</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>BNK Invest</td>\n",
       "      <td>https://www.nasdaq.com/articles/relative-stren...</td>\n",
       "      <td>\\nThe DividendRank formula at Dividend Channel...</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>Why Computer Stocks Fell Today</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>4.0</td>\n",
       "      <td>The Motley Fool</td>\n",
       "      <td>https://www.nasdaq.com/articles/why-computer-s...</td>\n",
       "      <td>\\nWhat happened\\nShares of prominent computer-...</td>\n",
       "      <td>AMD</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>INTC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  company                             titles release_date  weekday  \\\n",
       "0    AAPL  Relative Strength Alert For Apple   2020-02-27      4.0   \n",
       "1    AAPL     Why Computer Stocks Fell Today   2020-02-27      4.0   \n",
       "\n",
       "         publisher                                           page_url  \\\n",
       "0       BNK Invest  https://www.nasdaq.com/articles/relative-stren...   \n",
       "1  The Motley Fool  https://www.nasdaq.com/articles/why-computer-s...   \n",
       "\n",
       "                                             article other company 1  \\\n",
       "0  \\nThe DividendRank formula at Dividend Channel...            AAPL   \n",
       "1  \\nWhat happened\\nShares of prominent computer-...             AMD   \n",
       "\n",
       "  other company 2 other company 3 other company 4  \n",
       "0            None            None            None  \n",
       "1            AAPL            MSFT            INTC  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_fulllist_wide.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the duplicated news that have the same primary key (company, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_fulllist_wide.drop_duplicates(subset=['company','titles', 'release_date'],keep='first',inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the max length of titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "251"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(news_fulllist_wide['titles'].apply(lambda x: (len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(news_fulllist_wide['page_url'].apply(lambda x: (len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(news_fulllist_wide['company'].apply(lambda x: (len(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_fulllist_wide = news_fulllist_wide.where((pd.notnull(news_fulllist_wide)), None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to mysql and specifically the database named eBay\n",
    "mydb = mysql.connector.connect(host='127.0.0.1', user='root', buffered=True)\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"DROP DATABASE IF EXISTS news\")\n",
    "mycursor.execute(\"CREATE DATABASE news\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table of omdb if existed\n",
    "mydb = mysql.connector.connect(host='127.0.0.1', user='root', buffered=True, db='news')\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"DROP TABLE IF EXISTS nasdaq_news\")\n",
    "mycursor.execute(\"\"\"CREATE TABLE nasdaq_news\n",
    "(company VARCHAR(7), \n",
    "titles VARCHAR(251),\n",
    "release_date DATE,\n",
    "day_of_week INT,\n",
    "publisher VARCHAR(20),\n",
    "page_url VARCHAR(124),\n",
    "article LONGTEXT,\n",
    "other_company_1 VARCHAR(7),\n",
    "other_company_2 VARCHAR(7),\n",
    "other_company_3 VARCHAR(7),\n",
    "other_company_4 VARCHAR(7),\n",
    "PRIMARY KEY (company, titles, page_url) \n",
    ")\"\"\")\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53b5ffdac953428796e79bf72ec26776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4939.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Record saved.\n"
     ]
    }
   ],
   "source": [
    "# All the attributes we want to store in the database\n",
    "col = ['company', 'titles', 'release_date', 'day_of_week', 'publisher', 'page_url', 'article', 'other_company_1', 'other_company_2', 'other_company_3', 'other_company_4']\n",
    "# Insert data to the table\n",
    "into = \"INSERT INTO nasdaq_news(company, titles, release_date, day_of_week, publisher, page_url, article, other_company_1, other_company_2, other_company_3, other_company_4) values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "\n",
    "for i in notebook.tqdm(range(0, len(news_fulllist_wide))):\n",
    "    news = news_fulllist_wide.iloc[i,:]\n",
    "    if news['other company 1'] == 'None':\n",
    "        other_company_1 = None\n",
    "    elif news['other company 1'] is None:\n",
    "        other_company_1 = None\n",
    "    else:\n",
    "        other_company_1 = news['other company 1']\n",
    "        \n",
    "    if news['other company 2'] == 'None':\n",
    "        other_company_2 = None\n",
    "    elif news['other company 2'] == '':\n",
    "        other_company_2 = None\n",
    "    else: \n",
    "        other_company_2 = news['other company 2']\n",
    "        \n",
    "    if news['other company 3'] == 'None':\n",
    "        other_company_3 = None\n",
    "    elif news['other company 3'] == '':\n",
    "        other_company_3 = None\n",
    "    else: \n",
    "        other_company_3 = news['other company 3']\n",
    "    \n",
    "    if news['other company 4'] == 'None':\n",
    "        other_company_4 = None\n",
    "    elif news['other company 4'] == '':\n",
    "        other_company_4 = None\n",
    "    else: \n",
    "        other_company_4 = news['other company 4']\n",
    "        \n",
    "    if news['release_date'] == 'NaT':\n",
    "        release_date = None\n",
    "    else:\n",
    "        release_date = news['release_date']\n",
    "        \n",
    "    if news['weekday'] is None:\n",
    "        weekday = None\n",
    "    elif news['weekday'] is np.nan:\n",
    "        weekday = None\n",
    "    else:\n",
    "        weekday = news['weekday'].item()\n",
    "        \n",
    "    value = (news['company'], news['titles'], release_date, weekday, news['publisher'], news['page_url'], news['article'], other_company_1, other_company_2, other_company_3, other_company_4)\n",
    "    # Execute the insert command\n",
    "    mycursor.execute(into, value)\n",
    "    # Commit the execution\n",
    "    mydb.commit()\n",
    "\n",
    "print ('Record saved.')   \n",
    "# Close the database\n",
    "mydb.close()           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create a database for stock prices from APIs__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>1. open</th>\n",
       "      <th>2. high</th>\n",
       "      <th>3. low</th>\n",
       "      <th>4. close</th>\n",
       "      <th>5. adjusted close</th>\n",
       "      <th>6. volume</th>\n",
       "      <th>7. dividend amount</th>\n",
       "      <th>8. split coefficient</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>277.14</td>\n",
       "      <td>286.44</td>\n",
       "      <td>269.37</td>\n",
       "      <td>285.34</td>\n",
       "      <td>285.34</td>\n",
       "      <td>70721316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>263.75</td>\n",
       "      <td>278.09</td>\n",
       "      <td>263.00</td>\n",
       "      <td>266.17</td>\n",
       "      <td>266.17</td>\n",
       "      <td>71686208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  1. open  2. high  3. low  4. close  5. adjusted close  \\\n",
       "0  2020-03-10   277.14   286.44  269.37    285.34             285.34   \n",
       "1  2020-03-09   263.75   278.09  263.00    266.17             266.17   \n",
       "\n",
       "   6. volume  7. dividend amount  8. split coefficient company  \n",
       "0   70721316                 0.0                     1    AAPL  \n",
       "1   71686208                 0.0                     1    AAPL  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_fulllist.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conform the company columns to the same as those in news list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'AMZN', 'FB', 'TSLA', 'NFLX', 'GOOGL', 'ADBE', 'SBUX',\n",
       "       'EXPEDIA', 'COSTCO'], dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_fulllist['company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['AAPL', 'ADBE', 'AMZN', 'COSTCO', 'EXPEDIA', 'FB', 'GOOGL', 'NDAQ',\n",
       "       'NFLX', 'SBUX', 'TSLA'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_fulllist['company'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_fulllist.loc[api_fulllist.loc[:,'company'] == 'COST', 'company'] = 'COSTCO'\n",
    "api_fulllist.loc[api_fulllist.loc[:,'company'] == 'EXPE','company'] = 'EXPEDIA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the table of omdb if existed\n",
    "mydb = mysql.connector.connect(host='127.0.0.1', user='root', buffered=True, db='news')\n",
    "mycursor = mydb.cursor()\n",
    "mycursor.execute(\"DROP TABLE IF EXISTS stock_prices\")\n",
    "mycursor.execute(\"\"\"CREATE TABLE stock_prices\n",
    "(date_of_price DATE, \n",
    "open_price DECIMAL,\n",
    "high_price DECIMAL,\n",
    "low_price DECIMAL,\n",
    "close_price DECIMAL,\n",
    "adjusted_price DECIMAL,\n",
    "volume INT,\n",
    "dividend_amount DECIMAL,\n",
    "split_coef DECIMAL,\n",
    "company VARCHAR(7),\n",
    "PRIMARY KEY (company, date_of_price)\n",
    ")\"\"\")\n",
    "mydb.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7e000af12c94cb0aa92055e4be03cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1100.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Record saved.\n"
     ]
    }
   ],
   "source": [
    "# # All the attributes we want to store in the database\n",
    "# col = ['company', 'titles', 'release_date', 'day_of_week', 'publisher', 'page_url', 'article', 'other_company_1', 'other_company_2', 'other_company_3', 'other_company_4']\n",
    "# Insert data to the table\n",
    "into = \"INSERT INTO stock_prices(date_of_price, open_price, high_price, low_price, close_price, adjusted_price, volume, dividend_amount, split_coef, company) values (%s,%s,%s,%s,%s,%s,%s,%s,%s,%s)\"\n",
    "\n",
    "for i in notebook.tqdm(range(0, len(api_fulllist))):\n",
    "    price = api_fulllist.iloc[i,:]\n",
    "    value = (price['date'], price['1. open'].item(), price['2. high'].item(), price['3. low'].item(), price['4. close'].item(), price['5. adjusted close'].item(), price['6. volume'].item(), price['7. dividend amount'].item(), price['8. split coefficient'].item(), price['company'])\n",
    "    # Execute the insert command\n",
    "    mycursor.execute(into, value)\n",
    "    # Commit the execution\n",
    "    mydb.commit()\n",
    "\n",
    "print ('Record saved.')   \n",
    "# Close the database\n",
    "mydb.close()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
