{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import io\n",
    "\n",
    "import multiprocessing\n",
    "import statsmodels.api as sm\n",
    "import string \n",
    "\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem.porter import *\n",
    "\n",
    "from typing import List\n",
    "\n",
    "from sklearn import utils\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import re\n",
    "\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from gensim.models import word2vec\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.test.test_doc2vec import ConcatenatedDoc2Vec\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm._tqdm_notebook import tqdm_notebook\n",
    "tqdm_notebook.pandas()\n",
    "\n",
    "from tqdm import notebook\n",
    "import math\n",
    "\n",
    "\n",
    "from numpy.random import randn\n",
    "from numpy.random import seed\n",
    "from scipy.stats import pearsonr\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prepare the data__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mandy.txt', 'Mayank.txt', 'Teju.txt', 'Willa.txt']"
      ]
     },
     "execution_count": 484,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "for filename in glob.glob('*.txt'):\n",
    "    text.append(filename)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_txt_file(file):\n",
    "    '''\n",
    "    Get the content in the txt file\n",
    "    '''\n",
    "    with open(file, 'r') as f:\n",
    "        content = f.read()\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company</th>\n",
       "      <th>titles</th>\n",
       "      <th>release_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Relative Strength Alert For Apple</td>\n",
       "      <td>2/27/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Why Computer Stocks Fell Today</td>\n",
       "      <td>2/27/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2 Key Trends to Watch in Music Streaming</td>\n",
       "      <td>2/27/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (AAPL) Down 9.8% Since Last Earnings Rep...</td>\n",
       "      <td>2/27/2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple's Coronavirus Weakness Could Mean Invest...</td>\n",
       "      <td>2/27/2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index company                                             titles  \\\n",
       "0      0    AAPL                  Relative Strength Alert For Apple   \n",
       "1      1    AAPL                     Why Computer Stocks Fell Today   \n",
       "2      2    AAPL           2 Key Trends to Watch in Music Streaming   \n",
       "3      3    AAPL  Apple (AAPL) Down 9.8% Since Last Earnings Rep...   \n",
       "4      4    AAPL  Apple's Coronavirus Weakness Could Mean Invest...   \n",
       "\n",
       "  release_date  \n",
       "0    2/27/2020  \n",
       "1    2/27/2020  \n",
       "2    2/27/2020  \n",
       "3    2/27/2020  \n",
       "4    2/27/2020  "
      ]
     },
     "execution_count": 486,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines = pd.read_csv('news_full_list.csv', encoding = 'unicode_escape')\n",
    "headlines.reset_index(inplace = True)\n",
    "headlines = headlines[['index', 'company', 'titles', 'release_date']]\n",
    "headlines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_sentiment(df, titles):\n",
    "    sentiment_list = titles.split('\\n')\n",
    "    for sen in sentiment_list:\n",
    "        last_word = sen.split(' ')[-1]\n",
    "        try:\n",
    "            if int(last_word) in [0, 1, -1]:\n",
    "                index = int(sen.split('\\t')[0])\n",
    "                df.loc[index, 'sentiment'] = int(last_word)\n",
    "        except:\n",
    "            continue\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "for txt in ['Willa.txt', 'Mandy.txt', 'Teju.txt', 'Mayank.txt']:\n",
    "    titles = open_txt_file(txt)\n",
    "    headlines = parse_sentiment(headlines, titles)\n",
    "\n",
    "headlines = headlines.fillna('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def headlines_with_label(df):\n",
    "    '''\n",
    "    Retrive headlines with sentiment labelled\n",
    "    '''\n",
    "    label = df[df['sentiment'] != 'Unknown']\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.0    1759\n",
       " 1.0     721\n",
       "-1.0     372\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword = set(stopwords.words('english'))\n",
    "labelled_lines = headlines_with_label(headlines)\n",
    "labelled_lines.reset_index(drop = True, inplace = True)\n",
    "labelled_lines['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neu = labelled_lines[labelled_lines['sentiment'] == 0].iloc[:400]\n",
    "# pos = labelled_lines[labelled_lines['sentiment'] == 1].iloc[:400]\n",
    "# neg = labelled_lines[labelled_lines['sentiment'] == -1]\n",
    "# labelled = pd.concat([neu, pos, neg])\n",
    "# labelled.reset_index(drop = True, inplace = True)\n",
    "# labelled['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Incorporate pre-trained vectors__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_vectors(fname):\n",
    "#     fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "#     n, d = map(int, fin.readline().split())\n",
    "#     word_vector = {}\n",
    "#     for line in fin:\n",
    "#         tokens = line.rstrip().split(' ')\n",
    "#         word_vector[tokens[0]] = np.array(list(map(float, tokens[1:])))\n",
    "#     return word_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_vector = load_vectors('wiki-news-300d-1M.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(word_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Incorporate Doc2Vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(line):\n",
    "    line = str(line)\n",
    "    if line.strip()=='':\n",
    "        return ''\n",
    "    rule = re.compile(u\"[^a-zA-Z0-9\\u4E00-\\u9FA5]\")\n",
    "    line = rule.sub(' ',line)\n",
    "    return line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd610c8873ce4861a4db021705ac122b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2852.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "headlines_copy = headlines[headlines['sentiment'] != 'Unknown']\n",
    "headlines_copy['clean_titles'] = headlines_copy['titles'].progress_apply(remove_punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lowercase_remove_stopwords(text):\n",
    "    '''\n",
    "    Remove stop words\n",
    "    '''\n",
    "    text_without_stopwords = [word for word in text.lower().split(' ') if word not in stop_words]\n",
    "    return ' '.join(text_without_stopwords).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d292b869d449078514de8fbbd05623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2852.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "words = stopwords.words('english')\n",
    "punctuations = list(string.punctuation)\n",
    "stop_words = words + punctuations\n",
    "headlines_copy['clean_titles'] = headlines_copy['clean_titles'].progress_apply(lowercase_remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stemming(text):\n",
    "    '''\n",
    "    Stem all words by Porter\n",
    "    '''\n",
    "    plurals = text.split()\n",
    "    singles = [stemmer.stem(plural) for plural in plurals]\n",
    "    return ' '.join(singles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabc864a2ef44b1d84512f0cdaf399da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2852.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "headlines_copy['clean_titles'] = headlines_copy['clean_titles'].progress_apply(stemming)\n",
    "headlines_copy['clean_titles'] = headlines_copy['clean_titles'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DBOW__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = headlines_copy[headlines_copy['sentiment'] == 1]\n",
    "df_neg = headlines_copy[headlines_copy['sentiment'] == -1]\n",
    "df_majority = headlines_copy[headlines_copy['sentiment'] == 0]\n",
    "df_pos_unsampled = resample(df_pos, replace = True, n_samples = len(df_pos) * 2, random_state = 123)\n",
    "df_neg_unsampled = resample(df_neg, replace = True, n_samples = len(df_neg) * 5, random_state = 123)\n",
    "headlines_oversample = pd.concat([df_majority, df_pos_unsampled, df_neg_unsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.0    1860\n",
       " 0.0    1759\n",
       " 1.0    1442\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_oversample['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(headlines_oversample, test_size=0.3, random_state=42,stratify = headlines_oversample.sentiment.values)\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=r['clean_titles'], tags=[r['sentiment']]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=r['clean_titles'], tags=[r['sentiment']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1044080.73it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0,  negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1307190.92it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3554120.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3550722.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3419154.15it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3549026.46it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3547331.61it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3444522.32it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3551571.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3549874.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1778762.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1.33 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    " \n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.771560236998025\n",
      "Testing F1 score: 0.7708124610365406\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=3, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__DM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1775149.33it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dmm = Doc2Vec(dm=1, dm_mean=1, window=10, negative=5, min_count=1, workers=5, alpha=0.065, min_alpha=0.065)\n",
    "model_dmm.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1777272.97it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3435759.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1776635.35it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3551571.78it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3443723.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3437349.55it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1774301.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3554120.76it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 1183857.26it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 3542/3542 [00:00<00:00, 3542256.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(10):\n",
    "    model_dmm.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dmm.alpha -= 0.002\n",
    "    model_dmm.min_alpha = model_dmm.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.7419354838709677\n",
      "Testing F1 score: 0.7385351855572431\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dmm, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dmm, test_tagged)\n",
    " \n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Generate a new model__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dbow.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "model_dmm.delete_temporary_training_data(keep_doctags_vectors=True, keep_inference=True)\n",
    "new_model = ConcatenatedDoc2Vec([model_dbow, model_dmm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    " \n",
    "y_train, X_train = get_vectors(new_model, train_tagged)\n",
    "y_test, X_test = get_vectors(new_model, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.825543120473996\n",
      "Testing F1 score: 0.8236678971155529\n"
     ]
    }
   ],
   "source": [
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    " \n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Test for the result__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3598153f14bf4aa5a41929b8587583bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42ccfa6cbf524c93bc126d595151570a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d49f5ab907e64efcb547408400a849ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2148.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "non_labelled = headlines[headlines['sentiment'] == 'Unknown']\n",
    "non_labelled['clean_titles'] = non_labelled['titles'].progress_apply(remove_punctuation)\n",
    "non_labelled['clean_titles'] = non_labelled['titles'].progress_apply(lowercase_remove_stopwords)\n",
    "non_labelled['clean_titles'] = non_labelled['titles'].progress_apply(stemming)\n",
    "non_labelled['clean_titles'] = non_labelled['clean_titles'].apply(lambda x: x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company</th>\n",
       "      <th>titles</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Relative Strength Alert For Apple</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[rel, strength, alert, for, appl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Microsoft Stock Looks Ready for a Correction T...</td>\n",
       "      <td>2/24/2020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[microsoft, stock, look, readi, for, a, correc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>115</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Better Buy: Apple vs. Google</td>\n",
       "      <td>2/18/2020</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>[better, buy:, appl, vs., googl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>122</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple Cuts Its Revenue Guidance for Fiscal Q2</td>\n",
       "      <td>2/17/2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[appl, cut, it, revenu, guidanc, for, fiscal, Q2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>127</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Glu Mobile Surged on Earnings: Is It Time to B...</td>\n",
       "      <td>2/15/2020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[glu, mobil, surg, on, earnings:, Is, It, time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index company                                             titles  \\\n",
       "0      0    AAPL                  Relative Strength Alert For Apple   \n",
       "1     48    AAPL  Microsoft Stock Looks Ready for a Correction T...   \n",
       "2    115    AAPL                       Better Buy: Apple vs. Google   \n",
       "3    122    AAPL      Apple Cuts Its Revenue Guidance for Fiscal Q2   \n",
       "4    127    AAPL  Glu Mobile Surged on Earnings: Is It Time to B...   \n",
       "\n",
       "  release_date  sentiment                                       clean_titles  \n",
       "0    2/27/2020        0.0                  [rel, strength, alert, for, appl]  \n",
       "1    2/24/2020       -1.0  [microsoft, stock, look, readi, for, a, correc...  \n",
       "2    2/18/2020       -1.0                   [better, buy:, appl, vs., googl]  \n",
       "3    2/17/2020        0.0  [appl, cut, it, revenu, guidanc, for, fiscal, Q2]  \n",
       "4    2/15/2020        0.0  [glu, mobil, surg, on, earnings:, Is, It, time...  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged = non_labelled.apply(lambda r: TaggedDocument(words=r['clean_titles'], tags=[r['sentiment']]), axis=1)\n",
    "test = vec_for_learning(new_model, tagged)[1]\n",
    "pred = logreg.predict(test)\n",
    "\n",
    "non_labelled['sentiment'] = pred\n",
    "non_labelled.reset_index(drop = True, inplace = True)\n",
    "non_labelled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company</th>\n",
       "      <th>titles</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Relative Strength Alert For Apple</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[rel, strength, alert, for, appl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Why Computer Stocks Fell Today</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[comput, stock, fell, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2 Key Trends to Watch in Music Streaming</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, key, trend, watch, music, stream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (AAPL) Down 9.8% Since Last Earnings Rep...</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>-1</td>\n",
       "      <td>[appl, aapl, 9, 8, sinc, last, earn, report, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple's Coronavirus Weakness Could Mean Invest...</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[appl, coronaviru, weak, could, mean, investor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index company                                             titles  \\\n",
       "0      0    AAPL                  Relative Strength Alert For Apple   \n",
       "1      1    AAPL                     Why Computer Stocks Fell Today   \n",
       "2      2    AAPL           2 Key Trends to Watch in Music Streaming   \n",
       "3      3    AAPL  Apple (AAPL) Down 9.8% Since Last Earnings Rep...   \n",
       "4      4    AAPL  Apple's Coronavirus Weakness Could Mean Invest...   \n",
       "\n",
       "  release_date  sentiment                                       clean_titles  \n",
       "0    2/27/2020          0                  [rel, strength, alert, for, appl]  \n",
       "1    2/27/2020          0                       [comput, stock, fell, today]  \n",
       "2    2/27/2020          0              [2, key, trend, watch, music, stream]  \n",
       "3    2/27/2020         -1  [appl, aapl, 9, 8, sinc, last, earn, report, r...  \n",
       "4    2/27/2020          1  [appl, coronaviru, weak, could, mean, investor...  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_copy.reset_index(drop = True, inplace = True)\n",
    "\n",
    "headlines_sentiment = pd.concat([non_labelled, headlines_copy])\n",
    "headlines_sentiment = headlines_sentiment.sort_values('index')\n",
    "headlines_sentiment['sentiment'] = headlines_sentiment['sentiment'].apply(lambda x: int(x))\n",
    "headlines_sentiment.reset_index(drop = True, inplace = True)\n",
    "headlines_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "# headlines_sentiment.to_csv('Headlines with sentiments.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__xgboost__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors\n",
    " \n",
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = pd.DataFrame(X_train)\n",
    "y_train = list(y_train)\n",
    "X_test_df = pd.DataFrame(X_test)\n",
    "y_test = list(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.96%\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "model.fit(X_train_df, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_df)\n",
    "predictions = [round(value) for value in y_pred]\n",
    "\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Create word2vec__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_df = pd.read_csv('full_list_wweight.csv', encoding = 'unicode_escape')\n",
    "news_df = news_df.dropna()\n",
    "\n",
    "all_headlines = list(headlines['titles']) + list(news_df['article'])\n",
    "prg_title = [] \n",
    "  \n",
    "# iterate through each sentence in the file \n",
    "for i in all_headlines: \n",
    "    temp = [] \n",
    "      \n",
    "    # tokenize the sentence into words \n",
    "    for j in word_tokenize(i): \n",
    "        if j.isalpha():\n",
    "            temp.append(j.lower()) \n",
    "  \n",
    "    prg_title.append(temp) \n",
    "    \n",
    "headlines_model = word2vec.Word2Vec(prg_title, size=100,min_count=10,window=5)\n",
    "headlines_model.wv.save_word2vec_format(\"news_w2v.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_df['article'][0]\n",
    "# Strip some unnecessary words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rebound', 0.8655657768249512),\n",
       " ('drop', 0.855480432510376),\n",
       " ('rise', 0.8441327810287476),\n",
       " ('decline', 0.8367825746536255),\n",
       " ('surge', 0.8360257744789124),\n",
       " ('gain', 0.8251054883003235),\n",
       " ('jump', 0.8194429278373718),\n",
       " ('kick', 0.8179096579551697),\n",
       " ('miss', 0.8090846538543701),\n",
       " ('double', 0.7971330881118774)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_model.most_similar('fall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__LSTM__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_w2v(w2v_file):\n",
    "    \"\"\"\n",
    "    load w2v file and return gensim.models.word2vec.Word2Vec object\n",
    "    \"\"\"\n",
    "    \n",
    "    return KeyedVectors.load_word2vec_format(w2v_file, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_w2ix(w2v_model):\n",
    "    \"\"\"\n",
    "    Create a dictionary\n",
    "    \"\"\"\n",
    "    gensim_dict = Dictionary()\n",
    "    gensim_dict.doc2bow(w2v_model.wv.vocab.keys(), allow_update=True)\n",
    "    w2ix = {v: k + 1 for k, v in gensim_dict.items()}\n",
    "    \n",
    "    return w2ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ix_vec(sents: List[List[str]], w2ix):\n",
    "    \"\"\"\n",
    "    Transfer a file to index array\n",
    "    \"\"\"\n",
    "    new_sentences = []\n",
    "    for sen in sents:\n",
    "        new_sen = []\n",
    "        for word in sen:\n",
    "            try:\n",
    "                new_sen.append(w2ix[word])\n",
    "            except:\n",
    "                new_sen.append(0)\n",
    "        new_sentences.append(np.array(new_sen))\n",
    "\n",
    "    return np.array(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_w2ix_weight(index_dic, w2v_model):\n",
    "    \"\"\"\n",
    "    Generate weights from w2v corresponding to the dictionary\n",
    "    \"\"\"\n",
    "    weights = np.zeros((len(index_dic)+1, w2v_model.vector_size))\n",
    "    for w, index in index_dic.items():\n",
    "        weights[index, :] = w2v_model[w]\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the layer of LSTM\n",
    "def train_lstm(embedding_weights, x_train, y_train, x_test, y_test, **kwargs):    \n",
    "    print (u'Creating a model...')\n",
    "    model = Sequential()  # or Graph or whatever\n",
    "    model.add(Embedding(output_dim = 128,\n",
    "                        input_dim = W2IX_DIM,\n",
    "                        mask_zero = True,\n",
    "                        weights = [embedding_weights],\n",
    "                        input_length = INPUT_LEN,\n",
    "                       ))  # Adding Input Length\n",
    "    model.add(LSTM(input_dim=128, \n",
    "                   output_dim = kwargs.get('lstm_out_dim', 64), \n",
    "                   activation = kwargs.get('lstm_actv', 'tanh'),\n",
    "                   dropout=kwargs.get('lstm_drop_out', .2)))\n",
    "    model.add(Dropout(kwargs.get('drop_out', .3)))\n",
    "    model.add(Dense(output_dim=N_CLASS, activation=kwargs.get('dens_actv', 'softmax')))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    print (u'Compiling...')\n",
    "    sgd = optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss = 'categorical_crossentropy',\n",
    "                  optimizer = sgd,\n",
    "                  metrics = ['accuracy'])\n",
    "\n",
    "    print (u\"Training...\")\n",
    "    model.fit(x_train, y_train, batch_size = BATCH_SIZE, nb_epoch = EPOCH, validation_data = (x_test, y_test))\n",
    "\n",
    "    print (u\"Evalualting...\")\n",
    "    score, acc = model.evaluate(x_test, y_test, batch_size = BATCH_SIZE)\n",
    "    print ('Test score: %.3f' % score)\n",
    "    print ('Test accuracy: %.3f' % acc)\n",
    "    return model, kwargs.get('dens_actv', 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_txt = list(labelled_lines['titles'].apply(lambda x: x.lower()))\n",
    "all_lable = list(labelled_lines['sentiment'].apply(lambda x: str(int(x))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v = load_w2v(\"news_w2v.bin\")\n",
    "w2ix = gen_w2ix(w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define global variables\n",
    "N_CLASS = 3\n",
    "W2IX_DIM = len(w2ix) + 1\n",
    "EPOCH = 15\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4556"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tFeature Shapes:\n",
      "Train set: \t\t2139 \n",
      "Test set: \t\t713\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "titles = get_ix_vec(all_txt, w2ix)\n",
    "weights = gen_w2ix_weight(w2ix, w2v.wv)\n",
    "\n",
    "INPUT_LEN = max([len(l) for l in titles])\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(titles, np.array(all_lable))\n",
    "train_x = sequence.pad_sequences(train_x, INPUT_LEN)\n",
    "test_x = sequence.pad_sequences(test_x, INPUT_LEN)\n",
    "train_y = to_categorical(train_y,num_classes = N_CLASS)\n",
    "test_y = to_categorical(test_y,num_classes = N_CLASS)\n",
    "\n",
    "print(\"\\t\\t\\tFeature Shapes:\")\n",
    "print(\"Train set: \\t\\t{}\".format(len(train_x)), \"\\nTest set: \\t\\t{}\".format(len(test_x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a model...\n",
      "Compiling...\n",
      "Training...\n",
      "Train on 1356 samples, validate on 452 samples\n",
      "Epoch 1/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9670 - accuracy: 0.5885 - val_loss: 0.9135 - val_accuracy: 0.6084\n",
      "Epoch 2/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9315 - accuracy: 0.6047 - val_loss: 0.9128 - val_accuracy: 0.6084\n",
      "Epoch 3/15\n",
      "1356/1356 [==============================] - 9s 6ms/step - loss: 0.9295 - accuracy: 0.6047 - val_loss: 0.9110 - val_accuracy: 0.6084\n",
      "Epoch 4/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9260 - accuracy: 0.6047 - val_loss: 0.9128 - val_accuracy: 0.6084\n",
      "Epoch 5/15\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 0.9260 - accuracy: 0.6047 - val_loss: 0.9114 - val_accuracy: 0.6084\n",
      "Epoch 6/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9239 - accuracy: 0.6047 - val_loss: 0.9125 - val_accuracy: 0.6084\n",
      "Epoch 7/15\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 0.9244 - accuracy: 0.6047 - val_loss: 0.9106 - val_accuracy: 0.6084\n",
      "Epoch 8/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9238 - accuracy: 0.6047 - val_loss: 0.9093 - val_accuracy: 0.6084\n",
      "Epoch 9/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9260 - accuracy: 0.6047 - val_loss: 0.9100 - val_accuracy: 0.6084\n",
      "Epoch 10/15\n",
      "1356/1356 [==============================] - 9s 6ms/step - loss: 0.9208 - accuracy: 0.6047 - val_loss: 0.9103 - val_accuracy: 0.6084\n",
      "Epoch 11/15\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 0.9196 - accuracy: 0.6047 - val_loss: 0.9100 - val_accuracy: 0.6084\n",
      "Epoch 12/15\n",
      "1356/1356 [==============================] - 9s 7ms/step - loss: 0.9225 - accuracy: 0.6047 - val_loss: 0.9109 - val_accuracy: 0.6084\n",
      "Epoch 13/15\n",
      "1356/1356 [==============================] - 8s 6ms/step - loss: 0.9192 - accuracy: 0.6047 - val_loss: 0.9105 - val_accuracy: 0.6084\n",
      "Epoch 14/15\n",
      "1356/1356 [==============================] - 9s 6ms/step - loss: 0.9205 - accuracy: 0.6047 - val_loss: 0.9107 - val_accuracy: 0.6084\n",
      "Epoch 15/15\n",
      "1356/1356 [==============================] - 9s 6ms/step - loss: 0.9194 - accuracy: 0.6047 - val_loss: 0.9114 - val_accuracy: 0.6084\n",
      "Evalualting...\n",
      "452/452 [==============================] - 0s 924us/step\n",
      "Test score: 0.911\n",
      "Test accuracy: 0.608\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model = train_lstm(weights, train_x, train_y, test_x, test_y, dens_actv='sigmoid')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Validea Martin Zweig Strategy Daily Upgrade Report - 1/28/2020', array([0]))"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_txt = headlines['titles'][1210]\n",
    "test = sequence.pad_sequences([get_ix_vec([t_txt], w2ix)[0]], INPUT_LEN)\n",
    "headlines['titles'][1210], model.predict_classes(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Predictive power of sentiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since using Doc2vec (combined) & MNL generates the highest accuracy, we stick with this method, and try to investigate the prediction power of the sentiments on the following day's stock price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>adjusted close</th>\n",
       "      <th>vloume</th>\n",
       "      <th>dividend amount</th>\n",
       "      <th>split coef</th>\n",
       "      <th>company</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-03-10</td>\n",
       "      <td>277.14</td>\n",
       "      <td>286.44</td>\n",
       "      <td>269.37</td>\n",
       "      <td>285.34</td>\n",
       "      <td>285.34</td>\n",
       "      <td>70721316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-03-09</td>\n",
       "      <td>263.75</td>\n",
       "      <td>278.09</td>\n",
       "      <td>263.00</td>\n",
       "      <td>266.17</td>\n",
       "      <td>266.17</td>\n",
       "      <td>71686208</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>282.00</td>\n",
       "      <td>290.82</td>\n",
       "      <td>281.23</td>\n",
       "      <td>289.03</td>\n",
       "      <td>289.03</td>\n",
       "      <td>56544246</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2020-03-05</td>\n",
       "      <td>295.52</td>\n",
       "      <td>299.55</td>\n",
       "      <td>291.41</td>\n",
       "      <td>292.92</td>\n",
       "      <td>292.92</td>\n",
       "      <td>46893219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2020-03-04</td>\n",
       "      <td>296.44</td>\n",
       "      <td>303.40</td>\n",
       "      <td>293.13</td>\n",
       "      <td>302.74</td>\n",
       "      <td>302.74</td>\n",
       "      <td>54794568</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date    open    high     low   close  adjusted close    vloume  \\\n",
       "0  2020-03-10  277.14  286.44  269.37  285.34          285.34  70721316   \n",
       "1  2020-03-09  263.75  278.09  263.00  266.17          266.17  71686208   \n",
       "2  2020-03-06  282.00  290.82  281.23  289.03          289.03  56544246   \n",
       "3  2020-03-05  295.52  299.55  291.41  292.92          292.92  46893219   \n",
       "4  2020-03-04  296.44  303.40  293.13  302.74          302.74  54794568   \n",
       "\n",
       "   dividend amount  split coef company  \n",
       "0              0.0           1    AAPL  \n",
       "1              0.0           1    AAPL  \n",
       "2              0.0           1    AAPL  \n",
       "3              0.0           1    AAPL  \n",
       "4              0.0           1    AAPL  "
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read stock prices\n",
    "price = pd.read_excel('api_full.xlsx', encoding = 'cp1252')\n",
    "price.columns = ['date', 'open', 'high', 'low', 'close', 'adjusted close', 'vloume', 'dividend amount', 'split coef', 'company']\n",
    "price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>company</th>\n",
       "      <th>titles</th>\n",
       "      <th>release_date</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Relative Strength Alert For Apple</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[rel, strength, alert, for, appl]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Why Computer Stocks Fell Today</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[comput, stock, fell, today]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2 Key Trends to Watch in Music Streaming</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>0</td>\n",
       "      <td>[2, key, trend, watch, music, stream]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple (AAPL) Down 9.8% Since Last Earnings Rep...</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>-1</td>\n",
       "      <td>[appl, aapl, 9, 8, sinc, last, earn, report, r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Apple's Coronavirus Weakness Could Mean Invest...</td>\n",
       "      <td>2/27/2020</td>\n",
       "      <td>1</td>\n",
       "      <td>[appl, coronaviru, weak, could, mean, investor...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index company                                             titles  \\\n",
       "0      0    AAPL                  Relative Strength Alert For Apple   \n",
       "1      1    AAPL                     Why Computer Stocks Fell Today   \n",
       "2      2    AAPL           2 Key Trends to Watch in Music Streaming   \n",
       "3      3    AAPL  Apple (AAPL) Down 9.8% Since Last Earnings Rep...   \n",
       "4      4    AAPL  Apple's Coronavirus Weakness Could Mean Invest...   \n",
       "\n",
       "  release_date  sentiment                                       clean_titles  \n",
       "0    2/27/2020          0                  [rel, strength, alert, for, appl]  \n",
       "1    2/27/2020          0                       [comput, stock, fell, today]  \n",
       "2    2/27/2020          0              [2, key, trend, watch, music, stream]  \n",
       "3    2/27/2020         -1  [appl, aapl, 9, 8, sinc, last, earn, report, r...  \n",
       "4    2/27/2020          1  [appl, coronaviru, weak, could, mean, investor...  "
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f76e78bdd3f4358a57f0e5ee18d2223",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=11.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "price_company = list(price.company.unique())\n",
    "delta_company_prices = pd.DataFrame()\n",
    "for i in notebook.tqdm(price_company):\n",
    "    delta_company_price = price.loc[price['company'] == i, 'low'].diff(periods = -1).reset_index(drop = True)\n",
    "    delta_company_price = delta_company_price/price.loc[price['company'] == i, 'low'].reset_index(drop = True)\n",
    "    delta_company_prices = pd.concat([delta_company_prices, delta_company_price], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_company_prices.columns = price_company\n",
    "delta_company_prices = pd.concat([delta_company_prices, price.loc[0:100, 'date']], axis = 1)\n",
    "delta_company_prices = delta_company_prices.drop([99,100], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_company_prices.columns = ['AAPL', 'ADBE', 'AMZN','COSTCO', 'EXPEDIA', 'FB', 'GOOGL', 'NDAQ', 'NFLX', 'SBUX', 'TSLA', 'date']\n",
    "# the time range for price is 2019-10-17 ~ 2020-03-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Calculate every day's sentiment__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_weekend_news_to_Friday(company_model):\n",
    "    new_company_model = pd.DataFrame()\n",
    "    for i in range(1, len(company_model)):\n",
    "        new_level = company_model.iloc[i-1:i, :]\n",
    "        if math.isnan(new_level.iloc[:, 3]):\n",
    "            if len(new_company_model) != 0:\n",
    "                new_company_model.iloc[-1, 1] = new_company_model.iloc[-1, 1] + new_level.iloc[0,1]\n",
    "                new_company_model.iloc[-1, 2] = new_company_model.iloc[-1, 2] + new_level.iloc[0,2]\n",
    "        else:\n",
    "            new_company_model = pd.concat([new_company_model, new_level], axis = 0)\n",
    "    return(new_company_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a function that loops through all the companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_company_model (company_name):\n",
    "    company_sentiment = headlines_sentiment.loc[(headlines_sentiment['company'] == company_name) & (headlines_sentiment['release_date'] != 'Unknown'), ['sentiment','release_date']].groupby(['release_date']).agg({'sentiment':['sum', 'count']})\n",
    "    company_sentiment.reset_index(level=0, inplace=True)\n",
    "    company_date = pd.to_datetime(company_sentiment.loc[company_sentiment['release_date'] != ('Unknown'),'release_date'])\n",
    "    company_sentiment = pd.concat([company_date, company_sentiment['sentiment']], axis = 1)\n",
    "    company_sentiment = company_sentiment.sort_values(by = 'release_date')\n",
    "    company_price = delta_company_prices.loc[:,['date', company_name, 'NDAQ']].sort_values(by = 'date')\n",
    "    company_model = company_sentiment.set_index('release_date').join(company_price.set_index('date'))\n",
    "    company_model.reset_index(level=0, inplace=True)\n",
    "    company_model_full = add_weekend_news_to_Friday(company_model)\n",
    "    company_model_full['sentiment'] = company_model_full['sum']/company_model_full['count']\n",
    "    company_model_full.columns = ['date', 'sum', 'count', 'company', 'market', 'sentiment']\n",
    "    company_model_full['sentiment_yesterd'] = company_model_full['sentiment'].shift(1)\n",
    "    return company_model_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>company</th>\n",
       "      <th>market</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_yesterd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.006561</td>\n",
       "      <td>0.008779</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.003958</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.009538</td>\n",
       "      <td>0.006675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000878</td>\n",
       "      <td>0.007081</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>-2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.003031</td>\n",
       "      <td>-0.006396</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>0.002097</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2020-01-24</td>\n",
       "      <td>4</td>\n",
       "      <td>27</td>\n",
       "      <td>0.011660</td>\n",
       "      <td>0.005531</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>-0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2020-01-27</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>-0.037079</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.083333</td>\n",
       "      <td>0.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2020-01-28</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>0.020823</td>\n",
       "      <td>0.011739</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>-0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2020-01-29</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.028824</td>\n",
       "      <td>0.036106</td>\n",
       "      <td>0.190476</td>\n",
       "      <td>0.034483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2020-01-30</td>\n",
       "      <td>6</td>\n",
       "      <td>21</td>\n",
       "      <td>-0.011602</td>\n",
       "      <td>0.003014</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.190476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>-4</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.004370</td>\n",
       "      <td>0.005822</td>\n",
       "      <td>-0.173913</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>-2</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.029315</td>\n",
       "      <td>0.017579</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.173913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.019240</td>\n",
       "      <td>0.011145</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>-0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>-2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.015765</td>\n",
       "      <td>-0.008218</td>\n",
       "      <td>-0.117647</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2020-02-06</td>\n",
       "      <td>-2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>-0.017231</td>\n",
       "      <td>-0.153846</td>\n",
       "      <td>-0.117647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>-0.005628</td>\n",
       "      <td>-0.007997</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>-0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-02-10</td>\n",
       "      <td>-7</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.005753</td>\n",
       "      <td>-0.003884</td>\n",
       "      <td>-0.538462</td>\n",
       "      <td>0.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.007134</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.538462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-02-12</td>\n",
       "      <td>-1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>-0.014145</td>\n",
       "      <td>-0.062500</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-02-13</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>-0.001349</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>-0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-02-14</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>0.011613</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2020-02-18</td>\n",
       "      <td>-6</td>\n",
       "      <td>23</td>\n",
       "      <td>-0.019484</td>\n",
       "      <td>-0.000775</td>\n",
       "      <td>-0.260870</td>\n",
       "      <td>0.052632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2020-02-19</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.014850</td>\n",
       "      <td>0.009972</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.260870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>-0.013212</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.013107</td>\n",
       "      <td>-0.003032</td>\n",
       "      <td>-0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>-4</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.053488</td>\n",
       "      <td>-0.000260</td>\n",
       "      <td>-0.571429</td>\n",
       "      <td>-0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>-1</td>\n",
       "      <td>15</td>\n",
       "      <td>-0.005454</td>\n",
       "      <td>-0.000867</td>\n",
       "      <td>-0.066667</td>\n",
       "      <td>-0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.015610</td>\n",
       "      <td>-0.005756</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>-0.066667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sum  count   company    market  sentiment  sentiment_yesterd\n",
       "0  2020-01-15    1     13 -0.006561  0.008779   0.076923                NaN\n",
       "1  2020-01-16    1     23  0.000634  0.003958   0.043478           0.076923\n",
       "2  2020-01-17    0     26  0.009538  0.006675   0.000000           0.043478\n",
       "6  2020-01-21    5     11  0.000878  0.007081   0.454545           0.000000\n",
       "7  2020-01-22   -2     22  0.003031 -0.006396  -0.090909           0.454545\n",
       "8  2020-01-23   -1     13 -0.001346  0.002097  -0.076923          -0.090909\n",
       "9  2020-01-24    4     27  0.011660  0.005531   0.148148          -0.076923\n",
       "12 2020-01-27   -1     12 -0.037079 -0.000091  -0.083333           0.148148\n",
       "13 2020-01-28    1     29  0.020823  0.011739   0.034483          -0.083333\n",
       "14 2020-01-29    4     21  0.028824  0.036106   0.190476           0.034483\n",
       "15 2020-01-30    6     21 -0.011602  0.003014   0.285714           0.190476\n",
       "16 2020-01-31   -4     23 -0.004370  0.005822  -0.173913           0.285714\n",
       "19 2020-02-03   -2     13 -0.029315  0.017579  -0.153846          -0.173913\n",
       "20 2020-02-04    2     14  0.019240  0.011145   0.142857          -0.153846\n",
       "21 2020-02-05   -2     17  0.015765 -0.008218  -0.117647           0.142857\n",
       "22 2020-02-06   -2     13  0.001414 -0.017231  -0.153846          -0.117647\n",
       "23 2020-02-07    2     16 -0.005628 -0.007997   0.125000          -0.153846\n",
       "26 2020-02-10   -7     13 -0.005753 -0.003884  -0.538462           0.125000\n",
       "27 2020-02-11    0     11  0.007255  0.007134   0.000000          -0.538462\n",
       "28 2020-02-12   -1     16  0.010146 -0.014145  -0.062500           0.000000\n",
       "29 2020-02-13    1      6 -0.003065 -0.001349   0.166667          -0.062500\n",
       "30 2020-02-14    1     19 -0.000736  0.011613   0.052632           0.166667\n",
       "34 2020-02-18   -6     23 -0.019484 -0.000775  -0.260870           0.052632\n",
       "35 2020-02-19    0     12  0.014850  0.009972   0.000000          -0.260870\n",
       "36 2020-02-20    0     24  0.000246 -0.013212   0.000000           0.000000\n",
       "37 2020-02-21   -1     10 -0.013107 -0.003032  -0.100000           0.000000\n",
       "40 2020-02-24   -4      7 -0.053488 -0.000260  -0.571429          -0.100000\n",
       "41 2020-02-25   -1     15 -0.005454 -0.000867  -0.066667          -0.571429\n",
       "42 2020-02-26    3     13 -0.015610 -0.005756   0.230769          -0.066667"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AAPL_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "AAPL_model = create_company_model('AAPL')\n",
    "ADBE_model = create_company_model('ADBE')\n",
    "AMZN_model = create_company_model('AMZN')\n",
    "COST_model = create_company_model('COSTCO')\n",
    "EXPE_model = create_company_model('EXPEDIA')\n",
    "FB_model = create_company_model('FB')\n",
    "GOOGL_model = create_company_model('GOOGL')\n",
    "NFLX_model = create_company_model('NFLX')\n",
    "SBUX_model = create_company_model('SBUX')\n",
    "TSLA_model = create_company_model('TSLA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model = pd.concat([AAPL_model, ADBE_model, AMZN_model, COST_model, EXPE_model, FB_model, GOOGL_model, NFLX_model, SBUX_model, TSLA_model], axis = 0)\n",
    "full_model_nona = full_model.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>sum</th>\n",
       "      <th>count</th>\n",
       "      <th>company</th>\n",
       "      <th>market</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>sentiment_yesterd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-01-16</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0.008139</td>\n",
       "      <td>0.012804</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.076923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2020-01-17</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>0.009238</td>\n",
       "      <td>0.002314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2020-01-21</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.008626</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2020-01-22</td>\n",
       "      <td>-2</td>\n",
       "      <td>22</td>\n",
       "      <td>0.004128</td>\n",
       "      <td>-0.006930</td>\n",
       "      <td>-0.090909</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2020-01-23</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>-0.005259</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>-0.076923</td>\n",
       "      <td>-0.090909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>2020-02-20</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>-0.047771</td>\n",
       "      <td>-0.016590</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>2020-02-21</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.023295</td>\n",
       "      <td>0.005878</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-02-24</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.070847</td>\n",
       "      <td>-0.014236</td>\n",
       "      <td>-0.142857</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2020-02-25</td>\n",
       "      <td>-2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.044727</td>\n",
       "      <td>-0.004828</td>\n",
       "      <td>-0.400000</td>\n",
       "      <td>-0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2020-02-26</td>\n",
       "      <td>-3</td>\n",
       "      <td>8</td>\n",
       "      <td>-0.014032</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>-0.375000</td>\n",
       "      <td>-0.400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>567 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  sum  count   company    market  sentiment  sentiment_yesterd\n",
       "1  2020-01-16    1     23  0.008139  0.012804   0.043478           0.076923\n",
       "2  2020-01-17    0     26  0.009238  0.002314   0.000000           0.043478\n",
       "6  2020-01-21    5     11  0.003165  0.008626   0.454545           0.000000\n",
       "7  2020-01-22   -2     22  0.004128 -0.006930  -0.090909           0.454545\n",
       "8  2020-01-23   -1     13 -0.005259  0.002397  -0.076923          -0.090909\n",
       "..        ...  ...    ...       ...       ...        ...                ...\n",
       "92 2020-02-20    3      9 -0.047771 -0.016590   0.333333           0.222222\n",
       "93 2020-02-21    2      9  0.023295  0.005878   0.222222           0.333333\n",
       "96 2020-02-24   -1      7 -0.070847 -0.014236  -0.142857           0.222222\n",
       "97 2020-02-25   -2      5 -0.044727 -0.004828  -0.400000          -0.142857\n",
       "98 2020-02-26   -3      8 -0.014032  0.005513  -0.375000          -0.400000\n",
       "\n",
       "[567 rows x 7 columns]"
      ]
     },
     "execution_count": 538,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_nona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>company</td>     <th>  R-squared:         </th> <td>   0.016</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   9.402</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 15 Mar 2020</td> <th>  Prob (F-statistic):</th>  <td>0.00227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:35:17</td>     <th>  Log-Likelihood:    </th> <td>  1246.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   567</td>      <th>  AIC:               </th> <td>  -2488.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   565</td>      <th>  BIC:               </th> <td>  -2480.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "          <td></td>             <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>             <td>    0.0002</td> <td>    0.001</td> <td>    0.194</td> <td> 0.846</td> <td>   -0.002</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sentiment_yesterd</th> <td>    0.0094</td> <td>    0.003</td> <td>    3.066</td> <td> 0.002</td> <td>    0.003</td> <td>    0.015</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>664.974</td> <th>  Durbin-Watson:     </th>  <td>   1.975</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>155395.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-5.123</td>  <th>  Prob(JB):          </th>  <td>    0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>83.453</td>  <th>  Cond. No.          </th>  <td>    2.75</td> \n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                company   R-squared:                       0.016\n",
       "Model:                            OLS   Adj. R-squared:                  0.015\n",
       "Method:                 Least Squares   F-statistic:                     9.402\n",
       "Date:                Sun, 15 Mar 2020   Prob (F-statistic):            0.00227\n",
       "Time:                        21:35:17   Log-Likelihood:                 1246.1\n",
       "No. Observations:                 567   AIC:                            -2488.\n",
       "Df Residuals:                     565   BIC:                            -2480.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=====================================================================================\n",
       "                        coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------\n",
       "const                 0.0002      0.001      0.194      0.846      -0.002       0.003\n",
       "sentiment_yesterd     0.0094      0.003      3.066      0.002       0.003       0.015\n",
       "==============================================================================\n",
       "Omnibus:                      664.974   Durbin-Watson:                   1.975\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):           155395.513\n",
       "Skew:                          -5.123   Prob(JB):                         0.00\n",
       "Kurtosis:                      83.453   Cond. No.                         2.75\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = full_model_nona['company']\n",
    "X = full_model_nona['sentiment_yesterd']\n",
    "X_ = sm.add_constant(X)\n",
    "model = sm.OLS(Y, X_).fit()\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
